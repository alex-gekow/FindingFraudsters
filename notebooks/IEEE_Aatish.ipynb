{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self._data_path = \"../../ieee-fraud-detection/\"\n",
    "\n",
    "    def loadCsv(self, file_name):\n",
    "        with open(os.path.join(self._data_path, file_name)) as f:\n",
    "            csv = pd.read_csv(f)\n",
    "    \n",
    "        return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df):\n",
    "    df.columns = df.columns.str.replace('-', '_').str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()\n",
    "train_transaction = standardize_columns(dl.loadCsv(\"train_transaction.csv\"))\n",
    "train_identity = standardize_columns(dl.loadCsv(\"train_identity.csv\"))\n",
    "test_transaction = standardize_columns(dl.loadCsv(\"test_transaction.csv\"))\n",
    "test_identity = standardize_columns(dl.loadCsv(\"test_identity.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70452921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on TransactionID\n",
    "train = pd.merge(train_transaction, train_identity, on=\"TransactionID\", how=\"left\")\n",
    "test = pd.merge(test_transaction, test_identity, on=\"TransactionID\", how=\"left\")\n",
    "print(f\"Combined train shape: {train.shape}\")\n",
    "print(f\"Combined test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Preserve labels and identifiers ===\n",
    "y = train_transaction[['TransactionID', 'isFraud']].copy()  \n",
    "original_train_ids = train_transaction['TransactionID'].copy()\n",
    "original_test_ids = test_transaction['TransactionID'].copy()\n",
    "train.drop(columns=['isFraud'], inplace=True, errors='ignore')\n",
    "train['__dataset__'] = 'train'\n",
    "test['__dataset__'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protected_cols = ['TransactionID', '__dataset__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd61c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Concatenate train and test for unified processing ===\n",
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "print(f\"\\nCombined shape: {combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a64396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 5: Identify categorical and numerical columns ===\n",
    "cat_cols = combined.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumber of categorical columns: {len(cat_cols)}\")\n",
    "print(f\"Number of numerical columns: {len(num_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 5: Display Percentage of Missing Data ===\n",
    "missing_percent = combined.isnull().mean() * 100\n",
    "missing_summary = missing_percent.reset_index()\n",
    "missing_summary.columns = ['Feature', 'MissingPercent']\n",
    "missing_summary = missing_summary.sort_values(by='MissingPercent', ascending=False)\n",
    "\n",
    "print(\"\\nMissing Data Percentage Summary:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 6: Drop columns with >75% missing in combined ===\n",
    "missing_percent = combined.isnull().mean() * 100\n",
    "protected_cols = ['TransactionID', '__dataset__']\n",
    "high_missing_cols = [col for col in missing_percent[missing_percent > 70].index if col not in protected_cols]\n",
    "combined.drop(columns=high_missing_cols, inplace=True)\n",
    "print(f\"\\nDropped {len(high_missing_cols)} columns with >75% missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf914d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 7: Impute Numerical Columns ===\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "num_cols = [col for col in num_cols if col != 'TransactionID']\n",
    "missing_percent = combined[num_cols].isnull().mean() * 100\n",
    "\n",
    "low_missing = missing_percent[(missing_percent > 0) & (missing_percent <= 15)].index\n",
    "mid_missing = missing_percent[(missing_percent > 15) & (missing_percent <= 50)].index\n",
    "high_missing = missing_percent[(missing_percent > 50) & (missing_percent <= 70)].index\n",
    "\n",
    "print(f\"\\nLow missing (<=15%): {len(low_missing)}\")\n",
    "print(f\"Mid missing (<=50%): {len(mid_missing)}\")\n",
    "print(f\"High missing (<=75%): {len(high_missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40535f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "for col in low_missing:\n",
    "    combined[col] = combined[col].fillna(combined[col].mean())\n",
    "\n",
    "# Median Imputation\n",
    "for col in mid_missing:\n",
    "    combined[col] = combined[col].fillna(combined[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Imputation\n",
    "if len(high_missing) > 0:\n",
    "    print(\"\\nRunning IterativeImputer on high-missing numerical columns...\")\n",
    "    iterative = IterativeImputer(max_iter=10, random_state=0)\n",
    "    combined[high_missing] = iterative.fit_transform(combined[high_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 8: Impute Categorical Columns with Mode ===\n",
    "for col in cat_cols:\n",
    "    if col in combined.columns:\n",
    "        mode_val = combined[col].mode()[0] if not combined[col].mode().empty else 'missing'\n",
    "        combined[col] = combined[col].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5334c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 9: Encode Categorical Columns ===\n",
    "for col in cat_cols:\n",
    "    if col in combined.columns and col not in protected_cols:\n",
    "        combined[col] = combined[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nCleaned train shape: {combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 10: Split Combined Data Back into Train and Test ===\n",
    "print(\"\\n__dataset__ column in combined:\", '__dataset__' in combined.columns)\n",
    "print(\"Value counts for __dataset__:\\n\", combined['__dataset__'].value_counts())\n",
    "train_cleaned = combined[combined['__dataset__'] == 'train'].drop(columns='__dataset__').reset_index(drop=True)\n",
    "test_cleaned = combined[combined['__dataset__'] == 'test'].drop(columns='__dataset__').reset_index(drop=True)\n",
    "\n",
    "# Reattach target variable using TransactionID\n",
    "print(\"train_cleaned columns:\", train_cleaned.columns.tolist())\n",
    "print(\"y columns:\", y.columns.tolist())\n",
    "assert 'TransactionID' in train_cleaned.columns, \"TransactionID missing in train_cleaned\"\n",
    "assert 'TransactionID' in y.columns, \"TransactionID missing in y\"\n",
    "train_cleaned = pd.merge(train_cleaned, y, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 11: Final Checks ===\n",
    "print(\"\\nRemaining missing values in train:\", train_cleaned.isnull().sum().sum())\n",
    "print(\"Remaining missing values in test:\", test_cleaned.isnull().sum().sum())\n",
    "print(f\"\\nCleaned train shape: {train_cleaned.shape}\")\n",
    "print(f\"Cleaned test shape: {test_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 12: Check that original TransactionIDs match ===\n",
    "assert set(original_train_ids) == set(train_cleaned['TransactionID']), \"Mismatch in train TransactionIDs!\"\n",
    "assert set(original_test_ids) == set(test_cleaned['TransactionID']), \"Mismatch in test TransactionIDs!\"\n",
    "print(\"\\n TransactionID integrity check passed for both train and test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.1: Target Class Distribution ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='isFraud', data=train_cleaned)\n",
    "plt.title('Distribution of Fraudulent vs Non-Fraudulent Transactions')\n",
    "plt.xlabel('isFraud')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "fraud_rate = train_cleaned['isFraud'].mean()\n",
    "print(f\"Fraudulent transactions: {fraud_rate:.4f} ({fraud_rate * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0384e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.2: Summary Statistics ===\n",
    "print(\"\\nSummary statistics for numerical features:\")\n",
    "display(train_cleaned.describe())\n",
    "\n",
    "print(\"\\nNumber of unique values per feature:\")\n",
    "display(train_cleaned.nunique().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.3: Feature Correlation with isFraud ===\n",
    "correlations = train_cleaned.corr(numeric_only=True)['isFraud'].drop('isFraud').sort_values(key=abs, ascending=False)\n",
    "top_corr_features = correlations.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_corr_features.plot(kind='barh')\n",
    "plt.title('Top 20 Features Correlated with isFraud')\n",
    "plt.xlabel('Correlation')\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.4: Correlation Heatmap (Top Features) ===\n",
    "top_features = top_corr_features.index.tolist()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(train_cleaned[top_features + ['isFraud']].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Heatmap of Top Correlated Features with isFraud')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ab586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.5: Feature Distributions by isFraud ===\n",
    "important_feats = top_corr_features.head(5).index.tolist()\n",
    "\n",
    "for col in important_feats:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.kdeplot(data=train_cleaned, x=col, hue='isFraud', fill=True, common_norm=False)\n",
    "    plt.title(f'Distribution of {col} by isFraud')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 14.7: Chi-Square Test for Categorical Features ===\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "cat_cols_cleaned = [col for col in train_cleaned.columns if str(train_cleaned[col].dtype) in ['int8', 'int16', 'int32', 'int64']\n",
    "                    and train_cleaned[col].nunique() < 50 and col != 'isFraud']\n",
    "\n",
    "chi2_results = []\n",
    "\n",
    "for col in cat_cols_cleaned:\n",
    "    contingency_table = pd.crosstab(train_cleaned[col], train_cleaned['isFraud'])\n",
    "    if contingency_table.shape[0] > 1:  # skip degenerate cases\n",
    "        chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "        chi2_results.append((col, p))\n",
    "\n",
    "chi2_results = sorted(chi2_results, key=lambda x: x[1])\n",
    "print(\"Top categorical features by Chi-square p-value (lower is better):\")\n",
    "for col, p in chi2_results[:10]:\n",
    "    print(f\"{col}: p = {p:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8522d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct mapping for understanding what encoded values represent\n",
    "categorical_value_mappings = {}\n",
    "\n",
    "for col in cat_cols_cleaned:\n",
    "    # Attempt to map numeric value back to original label using group counts\n",
    "    value_counts = train[col].value_counts(dropna=False)  # original pre-encoded data if available\n",
    "    if train[col].dtype == 'object' or train[col].nunique() < 100:\n",
    "        value_map = train[[col]].drop_duplicates().reset_index(drop=True)\n",
    "        value_map['encoded'] = train_cleaned[col]\n",
    "        mapping = dict(zip(value_map['encoded'], value_map[col]))\n",
    "        categorical_value_mappings[col] = mapping\n",
    "\n",
    "# Print out a few mappings\n",
    "for col, mapping in list(categorical_value_mappings.items())[:5]:\n",
    "    print(f\"\\nMapping for {col}:\")\n",
    "    for k, v in sorted(mapping.items()):\n",
    "        print(f\"  {k} → '{v}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# === STEP 1: Encode categorical features and save mappings ===\n",
    "\n",
    "# Detect categorical columns\n",
    "categorical_cols = [col for col in train.columns\n",
    "                    if train[col].dtype == 'object' or (train[col].nunique() < 50 and col != 'isFraud')]\n",
    "\n",
    "label_encoders = {}\n",
    "encoding_maps = {}\n",
    "encoded_data = {}  # temp dict to hold encoded columns\n",
    "\n",
    "# Encode all categorical columns in one pass\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    encoded_col = le.fit_transform(train[col].astype(str))\n",
    "    encoded_data[col] = encoded_col\n",
    "    label_encoders[col] = le\n",
    "    encoding_maps[col] = {int(k): v for k, v in zip(le.transform(le.classes_), le.classes_)}\n",
    "\n",
    "# Combine all encoded columns into a new DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data, index=train.index)\n",
    "\n",
    "# Create a de-fragmented version of train_cleaned and update with encoded features\n",
    "train_cleaned = train_cleaned.copy()\n",
    "train_cleaned = pd.concat([train_cleaned.drop(columns=encoded_df.columns, errors='ignore'), encoded_df], axis=1)\n",
    "\n",
    "# Optionally save mappings to JSON\n",
    "with open(\"label_encoding_mappings.json\", \"w\") as f:\n",
    "    json.dump(encoding_maps, f, indent=2)\n",
    "\n",
    "# === STEP 2: Chi-Square Test for Categorical Features ===\n",
    "\n",
    "cat_cols_cleaned = [col for col in train_cleaned.columns\n",
    "                    if str(train_cleaned[col].dtype) in ['int8', 'int16', 'int32', 'int64']\n",
    "                    and train_cleaned[col].nunique() < 50 and col != 'isFraud']\n",
    "\n",
    "chi2_results = []\n",
    "\n",
    "for col in cat_cols_cleaned:\n",
    "    contingency_table = pd.crosstab(train_cleaned[col], train_cleaned['isFraud'])\n",
    "    if contingency_table.shape[0] > 1:\n",
    "        chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "        chi2_results.append((col, p))\n",
    "\n",
    "chi2_results = sorted(chi2_results, key=lambda x: x[1])\n",
    "\n",
    "print(\"Top categorical features by Chi-square p-value (lower is better):\")\n",
    "for col, p in chi2_results[:10]:\n",
    "    print(f\"{col}: p = {p:.4e}\")\n",
    "\n",
    "# === STEP 3: Plot Fraud Rate by Top Categorical Features ===\n",
    "\n",
    "for col, _ in chi2_results[:5]:  # adjust number as needed\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    fraud_rate = train_cleaned.groupby(col)['isFraud'].mean()\n",
    "\n",
    "    # Use original category labels if available\n",
    "    if col in encoding_maps:\n",
    "        x_labels = [encoding_maps[col].get(idx, str(idx)) for idx in fraud_rate.index]\n",
    "    else:\n",
    "        x_labels = fraud_rate.index.astype(str)\n",
    "\n",
    "    sns.barplot(x=x_labels, y=fraud_rate.values)\n",
    "    plt.title(f\"Fraud Rate by {col}\")\n",
    "    plt.ylabel(\"Fraud Rate\")\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===Fraud rate by category===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for col, _ in chi2_results[:5]:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    fraud_rate = train_cleaned.groupby(col)['isFraud'].mean()\n",
    "    sns.barplot(x=fraud_rate.index.astype(str), y=fraud_rate.values)\n",
    "    plt.title(f\"Fraud Rate by {col}\")\n",
    "    plt.ylabel(\"Fraud Rate\")\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Count vs Fraud rate ===\n",
    "\n",
    "for col, _ in chi2_results[:3]:\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.countplot(x=col, data=train_cleaned, ax=ax1, color='skyblue')\n",
    "    fraud_rate = train_cleaned.groupby(col)['isFraud'].mean()\n",
    "    ax2.plot(fraud_rate.index.astype(str), fraud_rate.values, color='red', marker='o')\n",
    "\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax2.set_ylabel('Fraud Rate')\n",
    "    plt.title(f\"Count and Fraud Rate by {col}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Categorical Grouped Fraud Rates ===\n",
    "grouped_rates = {}\n",
    "\n",
    "for col in cat_cols_cleaned:\n",
    "    group_mean = train_cleaned.groupby(col)['isFraud'].mean()\n",
    "    if group_mean.nunique() > 1:  # only keep meaningful differences\n",
    "        grouped_rates[col] = group_mean.sort_values(ascending=False)\n",
    "\n",
    "# Show a few examples\n",
    "for i, (col, rate_series) in enumerate(grouped_rates.items()):\n",
    "    print(f\"\\nFraud Rate by {col}:\")\n",
    "    print(rate_series)\n",
    "    if i >= 2:  # Limit output to top 3\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===  Feature Importance from LightGBM ===\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop non-predictive identifiers\n",
    "X = train_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
    "y = train_cleaned['isFraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importance\n",
    "lgb.plot_importance(model, max_num_features=20, importance_type='gain', figsize=(10, 6))\n",
    "plt.title('Top 20 Feature Importances (LightGBM)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Auto-bin & Encode High Cardinality Features ===\n",
    "high_cardinality = [col for col in train_cleaned.columns if train_cleaned[col].nunique() > 100 and col != 'TransactionID']\n",
    "\n",
    "# Frequency encoding\n",
    "for col in high_cardinality:\n",
    "    freq_map = train_cleaned[col].value_counts().to_dict()\n",
    "    train_cleaned[col + '_freq'] = train_cleaned[col].map(freq_map)\n",
    "    test_cleaned[col + '_freq'] = test_cleaned[col].map(freq_map)\n",
    "\n",
    "print(f\"Encoded {len(high_cardinality)} high-cardinality features with frequency encoding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LightGBM with Cross-Validation ===\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = train_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
    "y = train_cleaned['isFraud']\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, random_state=fold)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage AUC: {np.mean(auc_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865667cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SHAP Explanation ===\n",
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "# Summary plot for top features\n",
    "shap.summary_plot(shap_values, X_val, max_display=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c97776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 15.4 (Safe Version): Create a separate copy for feature engineering ===\n",
    "\n",
    "# Avoid modifying the original cleaned datasets\n",
    "train_feat = train_cleaned.copy()\n",
    "test_feat = test_cleaned.copy()\n",
    "\n",
    "interaction_features_train = []\n",
    "interaction_features_test = []\n",
    "interaction_feature_names = []\n",
    "\n",
    "# === Handle SHAP value format (supports both old and new SHAP versions) ===\n",
    "try:\n",
    "    # Newer SHAP returns Explanation objects\n",
    "    base_shap_values = shap_values.values\n",
    "except AttributeError:\n",
    "    base_shap_values = shap_values[1]  # binary classification, class 1\n",
    "\n",
    "# Recompute top SHAP features if needed\n",
    "shap_importance_base = np.abs(base_shap_values).mean(axis=0)\n",
    "top_indices = np.argsort(shap_importance_base)[-5:][::-1]\n",
    "top_shap_features = X_val.columns[top_indices].tolist()\n",
    "\n",
    "print(\"Top 5 features by SHAP importance (from original model):\")\n",
    "print(top_shap_features)\n",
    "\n",
    "# === Generate interaction features (ADD, SUB, MUL, DIV) from top SHAP features ===\n",
    "for i in range(len(top_shap_features)):\n",
    "    for j in range(i + 1, len(top_shap_features)):\n",
    "        f1 = top_shap_features[i]\n",
    "        f2 = top_shap_features[j]\n",
    "\n",
    "        new_add = f\"{f1}_plus_{f2}\"\n",
    "        new_sub = f\"{f1}_minus_{f2}\"\n",
    "        new_mul = f\"{f1}_times_{f2}\"\n",
    "        new_div = f\"{f1}_div_{f2}\"\n",
    "\n",
    "        interaction_feature_names.extend([new_add, new_sub, new_mul, new_div])\n",
    "\n",
    "        # Train interactions\n",
    "        train_inter = pd.DataFrame({\n",
    "            new_add: train_feat[f1] + train_feat[f2],\n",
    "            new_sub: train_feat[f1] - train_feat[f2],\n",
    "            new_mul: train_feat[f1] * train_feat[f2],\n",
    "            new_div: train_feat[f1] / (train_feat[f2] + 1e-5)\n",
    "        })\n",
    "\n",
    "        # Test interactions\n",
    "        test_inter = pd.DataFrame({\n",
    "            new_add: test_feat[f1] + test_feat[f2],\n",
    "            new_sub: test_feat[f1] - test_feat[f2],\n",
    "            new_mul: test_feat[f1] * test_feat[f2],\n",
    "            new_div: test_feat[f1] / (test_feat[f2] + 1e-5)\n",
    "        })\n",
    "\n",
    "        interaction_features_train.append(train_inter)\n",
    "        interaction_features_test.append(test_inter)\n",
    "\n",
    "# Concatenate all engineered features at once (fast and efficient)\n",
    "train_feat = pd.concat([train_feat] + interaction_features_train, axis=1)\n",
    "test_feat = pd.concat([test_feat] + interaction_features_test, axis=1)\n",
    "\n",
    "print(f\"\\n Added {len(interaction_feature_names)} interaction features to `train_feat` and `test_feat`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6034f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===SHAP Analysis With Interaction Features ===\n",
    "\n",
    "# Drop non-predictive columns\n",
    "X_feat = train_feat.drop(columns=['TransactionID', 'isFraud'], errors='ignore')\n",
    "y_feat = train_feat['isFraud']\n",
    "\n",
    "# Train a new LightGBM model using the feature-engineered data\n",
    "model_feat = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "model_feat.fit(X_feat, y_feat)\n",
    "\n",
    "# Create SHAP explainer and compute values\n",
    "explainer_feat = shap.TreeExplainer(model_feat)\n",
    "shap_vals_feat = explainer_feat.shap_values(X_feat)\n",
    "\n",
    "# Support newer SHAP versions (shap_values is a list for binary classification)\n",
    "if isinstance(shap_vals_feat, list) and len(shap_vals_feat) == 2:\n",
    "    shap_to_plot = shap_vals_feat[1]  # Class 1: isFraud\n",
    "else:\n",
    "    shap_to_plot = shap_vals_feat\n",
    "\n",
    "# === SHAP Summary Plot ===\n",
    "print(\"\\n SHAP Summary Plot With Interaction Features:\")\n",
    "shap.summary_plot(shap_to_plot, X_feat, max_display=20)\n",
    "\n",
    "# === Top SHAP Features Report ===\n",
    "shap_imp_feat = np.abs(shap_to_plot).mean(axis=0)\n",
    "top_feat_idx = np.argsort(shap_imp_feat)[-10:][::-1]\n",
    "top_feat_names = X_feat.columns[top_feat_idx].tolist()\n",
    "\n",
    "print(\"\\n Top SHAP features with interactions:\")\n",
    "print(top_feat_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train LightGBM and Plot ROC Curve ===\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X = train_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
    "y = train_cleaned['isFraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_scores = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_scores)\n",
    "auc = roc_auc_score(y_val, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=fpr, y=tpr, label=f\"LightGBM AUC = {auc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - LightGBM\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 16.2: Precision-Recall Curve ===\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_val, y_scores)\n",
    "avg_precision = average_precision_score(y_val, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=recall, y=precision, label=f\"Avg Precision = {avg_precision:.4f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve - LightGBM\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef643715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compare ROC Curves of LightGBM vs XGBoost ===\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_scores_xgb = model_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_val, y_scores_xgb)\n",
    "auc_xgb = roc_auc_score(y_val, y_scores_xgb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=fpr, y=tpr, label=f\"LightGBM AUC = {auc:.4f}\")\n",
    "sns.lineplot(x=fpr_xgb, y=tpr_xgb, label=f\"XGBoost AUC = {auc_xgb:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1692d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===Cross-Validated AUC ===\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model_cv = lgb.LGBMClassifier(n_estimators=100, random_state=fold)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    y_pred = model_cv.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Cross-Validated AUC: {np.mean(auc_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30643f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train Model Using Only Top SHAP Features (Before Interaction Engineering) ===\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure top_shap_features exists — redefine if needed\n",
    "try:\n",
    "    top_shap_features\n",
    "except NameError:\n",
    "    # Use original SHAP values from earlier session\n",
    "    try:\n",
    "        base_shap_values = shap_values.values\n",
    "    except AttributeError:\n",
    "        base_shap_values = shap_values[1]\n",
    "\n",
    "    shap_importance_base = np.abs(base_shap_values).mean(axis=0)\n",
    "    top_indices = np.argsort(shap_importance_base)[-5:][::-1]\n",
    "    top_shap_features = X_val.columns[top_indices].tolist()\n",
    "    print(\"Extracted top SHAP features (pre-feature engineering):\", top_shap_features)\n",
    "\n",
    "# Select only these features from train_cleaned\n",
    "X_base = train_cleaned[top_shap_features]\n",
    "y_base = train_cleaned['isFraud']\n",
    "\n",
    "# Train-test split\n",
    "Xb_train, Xb_val, yb_train, yb_val = train_test_split(X_base, y_base, stratify=y_base, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM\n",
    "model_base = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "model_base.fit(Xb_train, yb_train)\n",
    "\n",
    "# Predict\n",
    "yb_scores = model_base.predict_proba(Xb_val)[:, 1]\n",
    "auc_base = roc_auc_score(yb_val, yb_scores)\n",
    "fpr, tpr, _ = roc_curve(yb_val, yb_scores)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=fpr, y=tpr, label=f\"Top SHAP-only AUC = {auc_base:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SHAP Feature Subset\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compare ROC Curves Across Models Using All Features ===\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Prepare data\n",
    "X_all = train_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
    "y_all = train_cleaned['isFraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, stratify=y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define models\n",
    "models = {\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "}\n",
    "\n",
    "# 3. Train & evaluate\n",
    "plt.figure(figsize=(10, 7))\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_val, probs)\n",
    "    auc = roc_auc_score(y_val, probs)\n",
    "    sns.lineplot(x=fpr, y=tpr, label=f\"{name} (AUC = {auc:.4f})\")\n",
    "\n",
    "# 4. Plot random line for reference\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison - Full Feature Set\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ad07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68131607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LightGBM + Optuna Hyperparameter Tuning + ROC Curve ===\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare data\n",
    "X = train_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
    "y = train_cleaned['isFraud']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 128),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 50, 300),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    return auc\n",
    "\n",
    "# Start Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)  # You can increase to 50+ for better results\n",
    "\n",
    "# Best model\n",
    "best_params = study.best_params\n",
    "print(f\"\\n Best AUC: {study.best_value:.4f}\")\n",
    "print(\"Best parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Train final model with best params\n",
    "best_model = lgb.LGBMClassifier(**best_params, n_estimators=100, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_scores = best_model.predict_proba(X_val)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_val, y_scores)\n",
    "auc = roc_auc_score(y_val, y_scores)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=fpr, y=tpr, label=f\"Optimized LightGBM AUC = {auc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve After LightGBM Optimization (Optuna)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8d1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
