{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File paths ===\n",
    "DATA_PATH = \"../../ieee-fraud-detection/\"\n",
    "TRAIN_TRANS_FILE = \"train_transaction.csv\"\n",
    "TRAIN_IDENTITY_FILE = \"train_identity.csv\"\n",
    "TEST_TRANS_FILE = \"test_transaction.csv\"\n",
    "TEST_IDENTITY_FILE = \"test_identity.csv\"\n",
    "\n",
    "# === Load Data ===\n",
    "def load_data():\n",
    "    print(\"Loading train and test data...\")\n",
    "\n",
    "    train_transaction = pd.read_csv(os.path.join(DATA_PATH, TRAIN_TRANS_FILE))\n",
    "    train_identity = pd.read_csv(os.path.join(DATA_PATH, TRAIN_IDENTITY_FILE))\n",
    "    train = pd.merge(train_transaction, train_identity, how=\"left\", on=\"TransactionID\")\n",
    "\n",
    "    test_transaction = pd.read_csv(os.path.join(DATA_PATH, TEST_TRANS_FILE))\n",
    "    test_identity = pd.read_csv(os.path.join(DATA_PATH, TEST_IDENTITY_FILE))\n",
    "    test = pd.merge(test_transaction, test_identity, how=\"left\", on=\"TransactionID\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Load data\n",
    "train_raw, test_raw = load_data()\n",
    "train_raw.shape, test_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_types(df):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    return numerical_cols, categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_impute_fast(df, columns, max_iter=5, sample_frac=0.1, verbose=True):\n",
    "    df = df.copy()\n",
    "    if verbose:\n",
    "        print(f\"\\nâš¡ Fast Iterative Imputation: {len(columns)} columns | Sample: {sample_frac*100:.0f}% | Estimator: DecisionTree\\n\")\n",
    "\n",
    "    sample_df = df[columns].sample(frac=sample_frac, random_state=42)\n",
    "\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=DecisionTreeRegressor(max_depth=5),\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    imputer.fit(sample_df)\n",
    "    df[columns] = imputer.transform(df[columns])\n",
    "\n",
    "    print(\" Fast iterative imputation complete.\\n\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca97575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, target_column='isFraud'):\n",
    "    print(\" Cleaning data...\")\n",
    "    df = df.copy()\n",
    "    numerical_cols, categorical_cols = get_column_types(df)\n",
    "\n",
    "    if target_column in numerical_cols:\n",
    "        numerical_cols.remove(target_column)\n",
    "\n",
    "    # Calculate missing ratios\n",
    "    missing_ratios = df[numerical_cols].isnull().mean()\n",
    "\n",
    "    # Segmentation by % missing\n",
    "    iter_missing = missing_ratios[missing_ratios < 0.10].index.tolist()\n",
    "    mean_missing = missing_ratios[(missing_ratios >= 0.10) & (missing_ratios < 0.35)].index.tolist()\n",
    "    median_missing = missing_ratios[(missing_ratios >= 0.35) & (missing_ratios <= 0.70)].index.tolist()\n",
    "    high_missing = missing_ratios[missing_ratios > 0.70].index.tolist()\n",
    "\n",
    "    print(f\"Dropping {len(high_missing)} columns with >70% missing values...\")\n",
    "    df.drop(columns=high_missing, inplace=True)\n",
    "\n",
    "    # Iterative Imputer for very low-missing features\n",
    "    if iter_missing:\n",
    "        print(f\"Iteratively imputing {len(iter_missing)} columns (<10% missing)...\")\n",
    "        t0 = time.time()\n",
    "        df = iterative_impute_fast(df, iter_missing, max_iter=5, sample_frac=0.1, verbose=True)\n",
    "        print(f\" Iterative imputation complete in {time.time() - t0:.2f} seconds.\\n\")\n",
    "\n",
    "    # Mean Imputer for moderate-missing features\n",
    "    if mean_missing:\n",
    "        print(f\" Applying Mean Imputer to {len(mean_missing)} columns (10â€“35% missing)...\")\n",
    "        t1 = time.time()\n",
    "        mean_imp = SimpleImputer(strategy='mean')\n",
    "        df[mean_missing] = mean_imp.fit_transform(df[mean_missing])\n",
    "        print(f\" Mean imputation complete in {time.time() - t1:.2f} seconds.\\n\")\n",
    "\n",
    "    # Median Imputer for high-missing but usable features\n",
    "    if median_missing:\n",
    "        print(f\" Applying Median Imputer to {len(median_missing)} columns (35â€“70% missing)...\")\n",
    "        t2 = time.time()\n",
    "        median_imp = SimpleImputer(strategy='median')\n",
    "        df[median_missing] = median_imp.fit_transform(df[median_missing])\n",
    "        print(f\" Median imputation complete in {time.time() - t2:.2f} seconds.\\n\")\n",
    "\n",
    "    print(\" Data cleaning complete.\\n\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25891011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = clean_data(train_raw)\n",
    "train_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "X = train_cleaned.drop(columns=['isFraud'])\n",
    "y = train_cleaned['isFraud']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to category so LightGBM can handle them\n",
    "def prepare_lightgbm_data(X):\n",
    "    X = X.copy()\n",
    "    for col in X.select_dtypes(include='object').columns:\n",
    "        X[col] = X[col].astype('category')\n",
    "    return X\n",
    "\n",
    "X_train = prepare_lightgbm_data(X_train)\n",
    "X_val = prepare_lightgbm_data(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(X_train, y_train, X_val, y_val):\n",
    "    print(\" Training LightGBM model...\")\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature='auto')\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, categorical_feature='auto')\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 64,\n",
    "        'max_depth': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=['train', 'val'],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\" Model training complete.\\n\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef83b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(model, X_val, y_val):\n",
    "    print(\" Generating ROC curve...\")\n",
    "    y_proba = model.predict(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "    auc_score = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\", linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\" AUC Score: {auc_score:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lgb_model = train_lightgbm(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Plot ROC & AUC\n",
    "plot_roc_auc(lgb_model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# === 1. Check isFraud balance in train/val ===\n",
    "def check_fraud_distribution(y_train, y_val):\n",
    "    print(\" Fraud distribution:\")\n",
    "    print(f\"Train: {y_train.mean():.4f} ({y_train.sum()} frauds)\")\n",
    "    print(f\"Val:   {y_val.mean():.4f} ({y_val.sum()} frauds)\\n\")\n",
    "\n",
    "# === 2. Correlation with isFraud ===\n",
    "def check_feature_correlation(df):\n",
    "    print(\" Top features highly correlated with isFraud:\")\n",
    "    corr = df.corr(numeric_only=True)['isFraud'].sort_values(key=abs, ascending=False)\n",
    "    print(corr.head(10), \"\\n\")\n",
    "\n",
    "# === 3. Random prediction baseline ===\n",
    "def check_random_auc(y_val):\n",
    "    random_preds = np.random.rand(len(y_val))\n",
    "    auc_random = roc_auc_score(y_val, random_preds)\n",
    "    print(f\" Random Model AUC (baseline): {auc_random:.4f}\\n\")\n",
    "\n",
    "# === 4. Minimal feature model ===\n",
    "def check_baseline_model(X_train, y_train, X_val, y_val):\n",
    "    baseline_cols = [col for col in ['TransactionAmt', 'card1', 'card2', 'addr1'] if col in X_train.columns]\n",
    "    if not baseline_cols:\n",
    "        print(\" Baseline features not in data.\")\n",
    "        return\n",
    "    print(f\" Re-training with weak features only: {baseline_cols}\\n\")\n",
    "    X_base_train = X_train[baseline_cols]\n",
    "    X_base_val = X_val[baseline_cols]\n",
    "    \n",
    "    model = train_lightgbm(X_base_train, y_train, X_base_val, y_val)\n",
    "    plot_roc_auc(model, X_base_val, y_val)\n",
    "\n",
    "# === Run All Checks ===\n",
    "def run_sanity_checks(train_df, X_train, y_train, X_val, y_val):\n",
    "    check_fraud_distribution(y_train, y_val)\n",
    "    check_feature_correlation(train_df)\n",
    "    check_random_auc(y_val)\n",
    "    check_baseline_model(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# === Execute ===\n",
    "run_sanity_checks(train_cleaned, X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448caf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c352a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not installed\n",
    "# !pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ca0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop object columns (XGBoost can't handle categoricals directly)\n",
    "def prepare_xgb_data(X):\n",
    "    X = X.copy()\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    return X.fillna(-999)  # Safe placeholder for missing values\n",
    "\n",
    "X_train_xgb = prepare_xgb_data(X)\n",
    "y_train_xgb = y.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d06dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cross_validation(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "\n",
    "    print(f\" Starting {n_splits}-fold cross-validation...\\n\")\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=200,         # keep fixed to avoid early stopping\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            tree_method='hist'\n",
    "        )\n",
    "\n",
    "        # Set eval_metric via internal param update\n",
    "        model.set_params(eval_metric='auc')\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_proba)\n",
    "        aucs.append(auc)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "        tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "\n",
    "        print(f\"Fold {i+1} AUC: {auc:.4f}\")\n",
    "\n",
    "    print(f\"\\n Mean AUC: {np.mean(aucs):.4f} Â± {np.std(aucs):.4f}\")\n",
    "    return aucs, mean_fpr, tprs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_roc_cv(mean_fpr, tprs):\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=\"Mean ROC (CV)\", color='b')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Mean ROC Curve from XGBoost Cross-Validation\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs, mean_fpr, tprs = xgb_cross_validation(X_train_xgb, y_train_xgb, n_splits=5)\n",
    "plot_avg_roc_cv(mean_fpr, tprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only numeric columns (same as XGBoost) and fill missing values\n",
    "def prepare_lgbm_numeric(X):\n",
    "    X = X.copy()\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    return X.fillna(-999)  # Optional: LGBM can handle NaNs too\n",
    "\n",
    "X_train_lgbm_restricted = prepare_lgbm_numeric(X_train)\n",
    "X_val_lgbm_restricted = prepare_lgbm_numeric(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same LightGBM training function you already have\n",
    "lgb_model_restricted = train_lightgbm(\n",
    "    X_train_lgbm_restricted,\n",
    "    y_train,\n",
    "    X_val_lgbm_restricted,\n",
    "    y_val\n",
    ")\n",
    "\n",
    "# Plot ROC and print AUC\n",
    "plot_roc_auc(lgb_model_restricted, X_val_lgbm_restricted, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# === Fit encoder on training data ===\n",
    "def encode_full_dataset_fit(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # Force all categorical columns to string first\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    X[cat_cols] = X[cat_cols].astype(str)\n",
    "\n",
    "    # Encode categorical features\n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    X[cat_cols] = encoder.fit_transform(X[cat_cols])\n",
    "\n",
    "    # Ensure all columns are float\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    return X.fillna(-999), encoder\n",
    "\n",
    "# === Transform val/test data with fitted encoder ===\n",
    "def encode_full_dataset_transform(X, encoder):\n",
    "    X = X.copy()\n",
    "\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    X[cat_cols] = X[cat_cols].astype(str)\n",
    "    X[cat_cols] = encoder.transform(X[cat_cols])\n",
    "\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    return X.fillna(-999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05074e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded, encoder = encode_full_dataset_fit(X_train)\n",
    "X_val_encoded = encode_full_dataset_transform(X_val, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e275228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_full(X_train, y_train, X_val, y_val):\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        tree_method='hist'\n",
    "    )\n",
    "\n",
    "    model.set_params(eval_metric='auc')  # for older XGBoost versions\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_encoded = train_xgboost_full(X_train_encoded, y_train, X_val_encoded, y_val)\n",
    "\n",
    "# Evaluate\n",
    "y_proba = xgb_model_encoded.predict_proba(X_val_encoded)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "auc_score = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"XGBoost (Encoded) AUC = {auc_score:.4f}\", color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve â€“ XGBoost with Encoded Categorical Features\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\" AUC Score with Encoded XGBoost: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# Minimal retraining setup\n",
    "lgbm_sklearn_model = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_sklearn_model.fit(\n",
    "    X_train_lgbm_restricted, y_train,\n",
    "    eval_set=[(X_val_lgbm_restricted, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        early_stopping(50),\n",
    "        log_evaluation(100)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c525600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Predict probabilities ===\n",
    "y_proba_lgb = lgbm_sklearn_model.predict_proba(X_val_lgbm_restricted)[:, 1]\n",
    "y_proba_xgb = xgb_model_encoded.predict_proba(X_val_encoded)[:, 1]\n",
    "\n",
    "# === Compute PR curves ===\n",
    "precision_lgb, recall_lgb, _ = precision_recall_curve(y_val, y_proba_lgb)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_val, y_proba_xgb)\n",
    "# === Compute AUCs ===\n",
    "ap_lgb = average_precision_score(y_val, y_proba_lgb)\n",
    "ap_xgb = average_precision_score(y_val, y_proba_xgb)\n",
    "\n",
    "# === Plot PR curves ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_lgb, precision_lgb, label=f\"LightGBM (AP = {ap_lgb:.4f})\")\n",
    "plt.plot(recall_xgb, precision_xgb, label=f\"XGBoost (AP = {ap_xgb:.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve â€“ Fraud Detection\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, fbeta_score, classification_report,\n",
    "    balanced_accuracy_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# === Threshold for classification (you can tune this later)\n",
    "threshold = 0.5\n",
    "\n",
    "# === Convert probabilities to binary predictions\n",
    "y_pred_lgb = (y_proba_lgb >= threshold).astype(int)\n",
    "y_pred_xgb = (y_proba_xgb >= threshold).astype(int)\n",
    "\n",
    "# === F1 and FÎ² scores\n",
    "f1_lgb = f1_score(y_val, y_pred_lgb)\n",
    "f1_xgb = f1_score(y_val, y_pred_xgb)\n",
    "\n",
    "fbeta_lgb = fbeta_score(y_val, y_pred_lgb, beta=2)\n",
    "fbeta_xgb = fbeta_score(y_val, y_pred_xgb, beta=2)\n",
    "\n",
    "# === Balanced Accuracy\n",
    "bal_acc_lgb = balanced_accuracy_score(y_val, y_pred_lgb)\n",
    "bal_acc_xgb = balanced_accuracy_score(y_val, y_pred_xgb)\n",
    "\n",
    "# === Scikit-learn Reports\n",
    "print(\" LightGBM Classification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred_lgb, digits=4))\n",
    "\n",
    "print(\" XGBoost Classification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred_xgb, digits=4))\n",
    "\n",
    "# === Summary Output\n",
    "print(\"\\n Summary Metrics:\")\n",
    "\n",
    "print(f\"LightGBM\")\n",
    "print(f\"  F1 Score          : {f1_lgb:.4f}\")\n",
    "print(f\"  F2 Score (Î²=2)    : {fbeta_lgb:.4f}\")\n",
    "print(f\"  Balanced Accuracy : {bal_acc_lgb:.4f}\")\n",
    "\n",
    "print(f\"\\n XGBoost\")\n",
    "print(f\"  F1 Score          : {f1_xgb:.4f}\")\n",
    "print(f\"  F2 Score (Î²=2)    : {fbeta_xgb:.4f}\")\n",
    "print(f\"  Balanced Accuracy : {bal_acc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf55920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
    "\n",
    "thresholds = np.arange(0.05, 0.95, 0.01)\n",
    "precisions = []\n",
    "recalls = []\n",
    "f2_scores = []\n",
    "\n",
    "best_thresh = 0\n",
    "best_f2 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_proba_lgb >= t).astype(int)\n",
    "    p = precision_score(y_val, preds, zero_division=0)\n",
    "    r = recall_score(y_val, preds)\n",
    "    f2 = fbeta_score(y_val, preds, beta=2)\n",
    "    \n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f2_scores.append(f2)\n",
    "    \n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_thresh = t\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, recalls, label=\"Recall\", color=\"green\")\n",
    "plt.plot(thresholds, precisions, label=\"Precision\", color=\"blue\")\n",
    "plt.plot(thresholds, f2_scores, label=\"F2 Score\", color=\"purple\")\n",
    "plt.axvline(x=best_thresh, linestyle=\"--\", color=\"red\", label=f\"Best Threshold = {best_thresh:.2f}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"ðŸ” Threshold Sweep â€“ LightGBM\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Default threshold (0.5)\n",
    "preds_default = (y_proba_lgb >= 0.5).astype(int)\n",
    "recall_default = recall_score(y_val, preds_default)\n",
    "\n",
    "# Best threshold\n",
    "preds_best = (y_proba_lgb >= best_thresh).astype(int)\n",
    "recall_best = recall_score(y_val, preds_best)\n",
    "\n",
    "print(f\" Default Threshold (0.5) Recall      : {recall_default:.4f}\")\n",
    "print(f\" Best Threshold ({best_thresh:.2f}) Recall : {recall_best:.4f}\")\n",
    "print(f\" F2 Score at Best Threshold          : {best_f2:.4f}\")\n",
    "\n",
    "print(\"\\n Classification Report at Best Threshold:\\n\")\n",
    "print(classification_report(y_val, preds_best, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# AUC and AUPRC (threshold-independent)\n",
    "auc_lgb = roc_auc_score(y_val, y_proba_lgb)\n",
    "auprc_lgb = average_precision_score(y_val, y_proba_lgb)\n",
    "\n",
    "# Threshold-based predictions (you already chose 0.12)\n",
    "threshold = 0.12\n",
    "y_pred_thresh = (y_proba_lgb >= threshold).astype(int)\n",
    "\n",
    "# Confusion matrix at threshold\n",
    "cm = confusion_matrix(y_val, y_pred_thresh)\n",
    "\n",
    "print(f\" LightGBM Performance Summary (Threshold = {threshold:.2f})\")\n",
    "print(f\"AUC       : {auc_lgb:.4f}\")\n",
    "print(f\"AUPRC     : {auprc_lgb:.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_val, y_pred_thresh):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_val, y_pred_thresh):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_val, y_pred_thresh):.4f}\")\n",
    "print(f\"F2 Score  : {fbeta_score(y_val, y_pred_thresh, beta=2):.4f}\")\n",
    "print(f\"Balanced Accuracy : {balanced_accuracy_score(y_val, y_pred_thresh):.4f}\")\n",
    "\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf320a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_catboost(X):\n",
    "    X = X.copy()\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Replace NaNs with string 'missing' for object-type columns\n",
    "    for col in cat_cols:\n",
    "        X[col] = X[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "    return X, cat_cols.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb667a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cb, cat_features_cb = prepare_for_catboost(X_train)\n",
    "X_val_cb, _ = prepare_for_catboost(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01612343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "train_pool = Pool(X_train_cb, label=y_train, cat_features=cat_features_cb)\n",
    "val_pool = Pool(X_val_cb, label=y_val, cat_features=cat_features_cb)\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cat_model.fit(train_pool, eval_set=val_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_proba_cb = cat_model.predict_proba(X_val_cb)[:, 1]\n",
    "fpr_cb, tpr_cb, _ = roc_curve(y_val, y_proba_cb)\n",
    "auc_cb = roc_auc_score(y_val, y_proba_cb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_cb, tpr_cb, label=f\"CatBoost AUC = {auc_cb:.4f}\", color='purple')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve â€“ CatBoost\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\" Final CatBoost AUC: {auc_cb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5f73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Predict probabilities ===\n",
    "y_proba_lgb = lgbm_sklearn_model.predict_proba(X_val_lgbm_restricted)[:, 1]\n",
    "y_proba_xgb = xgb_model_encoded.predict_proba(X_val_encoded)[:, 1]\n",
    "y_proba_cat = cat_model.predict_proba(X_val_cb)[:, 1]\n",
    "\n",
    "# === Compute PR curves ===\n",
    "precision_lgb, recall_lgb, _ = precision_recall_curve(y_val, y_proba_lgb)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_val, y_proba_xgb)\n",
    "precision_cat, recall_cat, _ = precision_recall_curve(y_val, y_proba_cat)\n",
    "\n",
    "# === Compute AUCs ===\n",
    "ap_lgb = average_precision_score(y_val, y_proba_lgb)\n",
    "ap_xgb = average_precision_score(y_val, y_proba_xgb)\n",
    "ap_cat = average_precision_score(y_val, y_proba_cat)\n",
    "\n",
    "# === Plot PR curves ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_lgb, precision_lgb, label=f\"LightGBM (AP = {ap_lgb:.4f})\")\n",
    "plt.plot(recall_xgb, precision_xgb, label=f\"XGBoost (AP = {ap_xgb:.4f})\")\n",
    "plt.plot(recall_cat, precision_cat, label=f\"CatBoost (AP = {ap_cat:.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve â€“ Fraud Detection\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacc13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
